{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate a Random Poetry.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WTDYVQu8zcav"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZIRZ7YOggEhkQCYsPvx+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrohortencio/text-generator/blob/main/Poetry%20Generator/Generate_a_Random_Poetry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTDYVQu8zcav"
      },
      "source": [
        "# Construção do Modelo\n",
        "\n",
        "As duas células dessa sessão precisam ser executadas. Não precisa expandir e executar elas individualmente, basta apertar o _play button_ logo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuoK70bUyfb_"
      },
      "source": [
        "import urllib\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "# Pre-trained Model URL\n",
        "url_model = \"https://github.com/pedrohortencio/text-generator/blob/main/Poetry%20Generator/model-data/model-poetry-generator-ptbrV2.02.25041118.zip?raw=true\"\n",
        "# Tokenizer URL\n",
        "url_tokenizer = 'https://github.com/pedrohortencio/text-generator/blob/main/Poetry%20Generator/model-data/tokenizer.pickle?raw=true'\n",
        "\n",
        "# Download the tokenizer and model\n",
        "filename, headers = urllib.request.urlretrieve(url_model, filename=\"/content/model.zip\")\n",
        "filename, headers = urllib.request.urlretrieve(url_tokenizer, filename=\"/content/tokenizer.pickle\")\n",
        "\n",
        "# Unzip the model\n",
        "with zipfile.ZipFile('/content/model.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/model')\n",
        "\n",
        "# Loads the tokenizer\n",
        "with open('/content/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQQ6UNfRyWxt"
      },
      "source": [
        "def predictions(seed_text, next_words=50):\n",
        "\n",
        "    max_sequence_len = 12\n",
        "\n",
        "    # Loads the model\n",
        "    model = keras.models.load_model('/content/model/content/model')\n",
        "\n",
        "    \n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "        #predicted = model.predict_classes(token_list, verbose=0)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    seed_text = seed_text.replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" !\", \"!\").replace(\" ?\", \"?\").replace(\" :\", \":\")\n",
        "\n",
        "    return seed_text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdXnDG9Zze90"
      },
      "source": [
        "# Criação de (Quase) Poesias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHFR2YCZyj_5"
      },
      "source": [
        "print(\"Versão do Modelo: 2.01.0604.1841\")\n",
        "print(\"--\"*20)\n",
        "print(\"O gerador de poesias funciona com dois dados: seed e quantidade de palavras a serem geradas\")\n",
        "print(\"A seed é apenas uma frase curta que será o início da poesia. Sinta-se à vontade para digitar qualquer coisa.\")\n",
        "print(\"\\tNota: o modelo ainda está em fase de refinamento\")\n",
        "print(\"--\"*20, \"\\n\")\n",
        "\n",
        "while True:\n",
        "    print(\"Seed\")\n",
        "    seed = input(\"Digite uma frase curta: \")\n",
        "    try:\n",
        "        print(\"Número de palavras a serem geradas\")\n",
        "        num_words = int(input())\n",
        "    except:\n",
        "        num_words = 50\n",
        "\n",
        "    print(\"Gerando poesia\\n\", \"...\"*10)\n",
        "\n",
        "    poesia = predictions(seed, num_words)\n",
        "\n",
        "    print(\"Poesia gerada:\\n\\n\", poesia, \"\\n\")\n",
        "    print(\"...\"*10)\n",
        "\n",
        "    print('Prosseguir? (Digite \"pare\" para encerrar o loop)')\n",
        "    check = input()\n",
        "\n",
        "    if check.upper() == \"PARE\":\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}